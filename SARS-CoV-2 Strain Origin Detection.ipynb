{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasudevan773999/mate-2022-azure/blob/main/SARS-CoV-2%20Strain%20Origin%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ],
      "metadata": {
        "id": "6ph7C84G8-_r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i46RCXx_hCk9"
      },
      "source": [
        "# Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0doqIOEhJBC"
      },
      "source": [
        "In this colab, you will:\n",
        "*   Learn how to clean up and preprocess genome data\n",
        "*   Convert genomic data into a feature matrix\n",
        "*   Build a logistic regression model predicting the country a SARS-CoV-2 lineage came from based on its genome\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VJHN3yph4Uy",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6963badb-84a5-4707-f07f-0288a819c115"
      },
      "source": [
        "#@title Set up the notebook\n",
        "!pip install Biopython\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "from sklearn import model_selection, linear_model\n",
        "\n",
        "# data_path = 'https://drive.google.com/uc?id=1f1CtRwSohB7uaAypn8iA4oqdXlD_xXL1'\n",
        "# cov2_sequences = 'SARS_CoV_2_sequences_global.fasta'\n",
        "\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20DNA%20Detectives/SARS_CoV_2_sequences_global.fasta'\n",
        "cov2_sequences = 'SARS_CoV_2_sequences_global.fasta'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Biopython\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from Biopython) (1.22.4)\n",
            "Installing collected packages: Biopython\n",
            "Successfully installed Biopython-1.81\n",
            "SARS_CoV_2_sequence 100%[===================>]  44.77M   199MB/s    in 0.2s    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GVs1Qd_iMF3"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVl67ETxHK5"
      },
      "source": [
        "## Read in and examine the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4jSF-_jw3oz"
      },
      "source": [
        "We are going to read in a set of SARS-CoV-2 genomes from around the world. Note that sequence #0 is the \"reference sequence\"-- one of the original sequences from Wuhan. These global sequences come from the [NCBI database](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=SARS-CoV-2,%20taxid:2697049&SLen_i=29000%20TO%2031000&Completeness_s=complete&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606).  You can examine the different sequences using the form below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPJa6Gegnjw",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef1b87b-990f-4bb5-90dc-5768f00e9a79"
      },
      "source": [
        "sequences = [r for r in SeqIO.parse(cov2_sequences, 'fasta')]\n",
        "sequence_num =  0#@param {type:\"integer\"}\n",
        "print(sequences[sequence_num])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: NC_045512\n",
            "Name: NC_045512\n",
            "Description: NC_045512 |Severe acute respiratory syndrome coronavirus 2 isolate Wuhan-Hu-1| complete genome|China\n",
            "Number of features: 0\n",
            "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQdJz8Yyz5t"
      },
      "source": [
        "###**Exercise: How many sequences are there?**\n",
        "\n",
        "Note: Sequences have been uploaded/stored in a variable called ```sequences```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6mli7Gyz5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e252acbd-85a2-4fde-9ddb-2ebfafa23f9e"
      },
      "source": [
        "n_sequences = len(sequences)\n",
        "print(\"There are %.0f sequences\" % n_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1538 sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6cnVm9ExOGu"
      },
      "source": [
        "###**Exercise: How different are the 1st (non-reference) and 10th SARS-CoV-2 sequences?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwJlRubxicM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc7e093-1337-4458-ad0c-23cec76d5987"
      },
      "source": [
        "sequence_1 = np.array(sequences[0])\n",
        "sequence_10 = np.array(sequences[9])\n",
        "percent_similarity =  100*sum(sequence_1==sequence_10)/len(sequence_1)\n",
        "print(\"Sequence 1 and 10 similarity: %\", percent_similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence 1 and 10 similarity: % 99.9765909774939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqVhusUxJj6"
      },
      "source": [
        "### **Exercise (BONUS):  Make a histogram of the number of mutations each SARS-CoV-2 sequence has compared to the reference genome.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgCNKdJ2O4l"
      },
      "source": [
        "Interestingly, it looks like there are a couple sequences with a LOT of mutations! We can investigate these sequences a little more.\n",
        "\n",
        "**Examine some of these sequences with high number of mutations by selecting the minimum # of mutations from the form below. What do you notice about the sequences? Discuss with your instructor and peers.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VSB3eTzJT0",
        "cellView": "form"
      },
      "source": [
        "min_number_of_mutations  =  340#@param {type:\"integer\"}\n",
        "idx = np.random.choice(np.where(mutations_per_seq>min_number_of_mutations)[0])\n",
        "print(\"Sequence %i has > %.0f mutations! \\n\" % (idx, min_number_of_mutations))\n",
        "print(sequences[idx], '\\n')\n",
        "print(\"The sequence is composed of: \")\n",
        "Counter(np.array(sequences[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3_3xSpe20IT"
      },
      "source": [
        "## Missing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgzI9GyD2h9b"
      },
      "source": [
        "It is hard to see, but some of the sequences have `N` in them. Run the cell below for an example\n",
        "\n",
        "### **Exercise: Calculate the number of sequences that have an ```N``` in them.**\n",
        "\n",
        "**What do you think ```N``` means?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWw4fp1w3MRJ"
      },
      "source": [
        "n_sequences_with_N = np.sum(np.sum(sequences_np=='N',axis=1) > 0)\n",
        "\n",
        "print('%i sequences have at least 1 \"N\"!' % n_sequences_with_N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eno1YJJo2flS"
      },
      "source": [
        "\n",
        "`N` is not a nucleic acid- it just stands for \"missing\", or \"low quality\". \"Missing\" is different than ```_``` or a deletion. At the locations with ```N```, the sequencing machine had low quality data here, so it was unable to determine what base was at that location. We should remember this when we extract our features. Stay tuned for more on sequencing machines and how sequences are built in the bonus colab of this project!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4r8Qk64P1n"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "We are going to build a model that predicts the country a SARS-CoV-2 virus came from based on its genome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD96VzFr65jR"
      },
      "source": [
        "### **Exercise: Recall the structure of machine learning models.**\n",
        "**In general what two categories of data do we need to build a supervised machine learning model? What will we use for each category?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJga_xZ_MP4"
      },
      "source": [
        "_1_  =  'Sequences --> ' #@param {type:\"string\"}\n",
        "_2_  =  'Location --> a list of binary values' #@param {type:\"string\"}\n",
        "\n",
        "print('1. We need a set of FEATURES (X).\\n',\n",
        "      '  Our features will be the genomes of the different sequences.')\n",
        "print('2. We need LABElS (Y).\\n',\n",
        "      '  Our labels will be the country that each sequence came from.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrHyaErMp9fB"
      },
      "source": [
        "**Question: How will we turn our features into a numeric matrix?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A72g_7uSyVP"
      },
      "source": [
        "## Extract Features (X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ZU8b4fdXo6"
      },
      "source": [
        "Remember that our input must be a *numeric* matrix/table.\n",
        "We are going to create a matrix where our features are the presence/absence of a specific mutation (given by ```<location>```_```<base>```).  \n",
        "\n",
        "Our columns will be 1_A, 1_T, 3_G, 4_A, etc.\n",
        "\n",
        "\n",
        "| Sequence ID | 1_A | 1_C | 3_G | 4_A  | ...|\n",
        "|-------------|-----|-----|-----|------|----|\n",
        "|Sequence 1   |  1  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 2   |  0  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 3   |  1  |  0  |   0 |    0 |  0 |\n",
        "|Sequence 4   |  0  |  1  |   0 |    1 |  1 |\n",
        "|Sequence 5   |  1  |  0  |   0 |    0 |  1 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTy_D41nBYe-"
      },
      "source": [
        "# Note: This can take a couple minutes to run!\n",
        "# but we can monitor our progress using the tqdm library (which creates a progress bar)\n",
        "n_bases_in_seq = len(sequences[0])\n",
        "columns = {}\n",
        "\n",
        "# Iterate though all positions in this sequence.\n",
        "for location in tqdm.tqdm(range(n_bases_in_seq)): # tqdm is a nice library that prints our progress.\n",
        "  bases_at_location = np.array([s[location] for s in sequences])\n",
        "  # If there are no mutations at this position, move on.\n",
        "  if len(set(bases_at_location))==1: continue\n",
        "  for base in ['A', 'T', 'G', 'C', '-']:\n",
        "    feature_values = (bases_at_location==base)\n",
        "\n",
        "    # Set the values of any base that equals 'N' to np.nan.\n",
        "    feature_values[bases_at_location==['N']] = np.nan\n",
        "\n",
        "    # Convert from T/F to 0/1.\n",
        "    feature_values  = feature_values*1\n",
        "\n",
        "    # Make the column name look like <location>_<base> (1_A, 2_G, 3_A, etc.)\n",
        "    column_name = str(location) + '_' + base\n",
        "\n",
        "    # Add column to dict\n",
        "    columns[column_name] = feature_values\n",
        "\n",
        "\n",
        "mutation_df = pd.DataFrame(columns)\n",
        "\n",
        "# Print the size of the feature matrix/table.\n",
        "n_rows = np.shape(mutation_df)[0]\n",
        "n_columns = np.shape(mutation_df)[1]\n",
        "print(\"Size of matrix: %i rows x %i columns\" %(n_rows, n_columns))\n",
        "\n",
        "# Check what the matrix looks like:\n",
        "mutation_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrC_ymFoSs_g"
      },
      "source": [
        "## Extract Label (Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQVTqPhIYUr"
      },
      "source": [
        "We are going to use the region of the world that each sample came from as the **label**. ![alt text](https://upload.wikimedia.org/wikipedia/commons/3/3d/Flag-map_of_the_world_%282017%29.png)\n",
        "\n",
        "First, let's see how many samples we have from different countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxL3w1MHFx0k",
        "cellView": "form"
      },
      "source": [
        "#@title ###**Exercise: Explore the different number of samples that come from each country.**\n",
        "country = \"Pakistan\" #@param dict_keys(['China', 'Kazakhstan', 'India', 'Sri Lanka', 'Taiwan', 'Hong Kong', 'Viet Nam', 'Thailand', 'Nepal', 'Israel', 'South Korea', 'Iran', 'Pakistan', 'Turkey', 'Australia', 'USA']\n",
        "countries = [(s.description).split('|')[-1] for s in sequences]\n",
        "print(\"There are %i sequences from %s.\" %\n",
        "      (Counter(countries)[country], country))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu2QZpFdzGG"
      },
      "source": [
        "Since some countries only have a couple samples, we are going to use the **region** of the world as our labels.\n",
        "\n",
        "Since we have a large number of samples from Asia, North America, and Oceania, we will filter ours sequences to just these regions. We will convert our countries to regions using the code below.\n",
        "\n",
        "### **Exercise: Convert each country to its region of the world.**\n",
        "**Use the code below to create a dictionary of ```<country>```:```<region>``` where ```region``` is either ```'Oceania'```, ```'North America'```, or ```'Asia'```, and convert each country to region.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODOhep8g8LCB",
        "cellView": "both"
      },
      "source": [
        "countries_to_regions_dict = {\n",
        "         'Australia': 'Oceania',\n",
        "         'China': 'Asia',\n",
        "         'Hong Kong': 'Asia',\n",
        "         'India': 'Asoa' ,\n",
        "         'Nepal': 'Asia' ,\n",
        "         'South Korea': 'Asia' ,\n",
        "         'Sri Lanka': 'Asia' ,\n",
        "         'Taiwan': 'Asia' ,\n",
        "         'Thailand': 'Asia' ,\n",
        "         'USA': 'North America' ,\n",
        "         'Viet Nam': 'Asia'\n",
        "}\n",
        "\n",
        "regions = [countries_to_regions_dict[c] if c in\n",
        "           countries_to_regions_dict else 'NA' for c in countries]\n",
        "mutation_df['label'] = regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXuNJGj0K94L"
      },
      "source": [
        "**Now see how many samples there are from each region of the world.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8xUF_S-K809"
      },
      "source": [
        "region = \"Oceania\" #@param ['Oceania', 'North America', 'Asia']\n",
        "print(\"There are %i sequences from %s.\" %\n",
        "      (Counter(regions)[region], region))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxVN5LnFLX4X"
      },
      "source": [
        "## Balancing the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCfkZVGnkCLL"
      },
      "source": [
        "Recall that ML models work the best if we have *balanced* data - a dataset with equal numbers of samples with each label. Run the following code to remove duplicate samples from the dataset, and then balance the samples.\n",
        "\n",
        "### **Exercise: Balance the data equally between samples from Asia, Oceania, and North America**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsGQiLUzL0hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa5bf7c-393a-4086-ea9c-9801dd8e2da5"
      },
      "source": [
        "balanced_df = mutation_df.copy()\n",
        "balanced_df['label'] = regions\n",
        "balanced_df = balanced_df[balanced_df.label!='NA']\n",
        "balanced_df = balanced_df.drop_duplicates()\n",
        "samples_north_america = balanced_df[balanced_df.label== 'North America' ]\n",
        "samples_oceania = balanced_df[balanced_df.label== 'Oceania' ]\n",
        "samples_asia = balanced_df[balanced_df.label== 'Asia']\n",
        "\n",
        "# Number of samples we will use from each region.\n",
        "n = min(len(samples_north_america),\n",
        "        len(samples_oceania),\n",
        "        len(samples_asia))\n",
        "\n",
        "balanced_df = pd.concat([samples_north_america[:n],\n",
        "                    samples_asia[:n],\n",
        "                    samples_oceania[:n]])\n",
        "print(\"Number of samples in each region: \", Counter(balanced_df['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in each region:  Counter({'North America': 109, 'Asia': 109, 'Oceania': 109})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJBRsrulXnUG"
      },
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwZJYgOxQx11"
      },
      "source": [
        "***Congrats!***  We finally are done with preprocessing/cleaning our data! Although tedious, this is an important part of doing machine learning in biology. The data can be complex and messy, and if we don't do some cleaning up beforehand, our models will have poor performance.\n",
        "\n",
        "\n",
        "![](https://media.makeameme.org/created/we-did-it-3b3ac27d2a.jpg)\n",
        "\n",
        "\n",
        "Finally, run the code to set up a ```X``` feature matrix and a ```Y``` label list from our ```balanced_df```. You can explore the different values using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Ebb7WuO1Oq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657728db-e6ac-47d9-89b3-0fc2acd93d67"
      },
      "source": [
        "X = balanced_df.drop('label', axis=1)\n",
        "Y = balanced_df.label\n",
        "data = \"X (features)\" #@param ['X (features)', 'Y (label)']\n",
        "start = 1 #@param {type:'integer'}\n",
        "stop =  10#@param {type:'integer'}\n",
        "\n",
        "if start>=stop:print(\"Start must be < stop!\")\n",
        "else:\n",
        "  if data=='X (features)':\n",
        "    print(X.iloc[start:stop])\n",
        "  if data=='Y (label)':\n",
        "    print(Y[start:stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0_A  0_T  0_G  0_C  0_-  1_A  1_T  1_G  1_C  1_-  ...  29901_A  29901_T  \\\n",
            "323    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "324    0    0    1    0    0    0    1    0    0    0  ...        1        0   \n",
            "325    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "326    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "327    0    0    1    0    0    0    1    0    0    0  ...        0        0   \n",
            "328    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "329    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "330    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "331    1    0    0    0    0    0    1    0    0    0  ...        0        0   \n",
            "\n",
            "     29901_G  29901_C  29901_-  29902_A  29902_T  29902_G  29902_C  29902_-  \n",
            "323        0        0        1        0        0        0        0        1  \n",
            "324        0        0        0        1        0        0        0        0  \n",
            "325        0        0        1        0        0        0        0        1  \n",
            "326        0        0        1        0        0        0        0        1  \n",
            "327        0        0        1        0        0        0        0        1  \n",
            "328        0        0        1        0        0        0        0        1  \n",
            "329        0        0        1        0        0        0        0        1  \n",
            "330        0        0        1        0        0        0        0        1  \n",
            "331        0        0        1        0        0        0        0        1  \n",
            "\n",
            "[9 rows x 12680 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDviuy5wc3-e"
      },
      "source": [
        "In preparation for training and testing our model, we need to import two key functions:\n",
        "\n",
        "* `train_test_split()`, used to split the data into training and testing portions, and\n",
        "* `accuracy_score()`, for testing the accuracy of our model's predictions against the labels in our testing data.\n",
        "\n",
        "Run the next code block to import these functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2-pzKByc41O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4fAOFq3iqFl"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcksFwDLlOsE"
      },
      "source": [
        "We will be using the logistic regression model we have learned about with one modification. We will use the \"multinomial\" class of logistic regression model.  This is used when there are more than 2 categories in the label set. In our case, we have ```Asia```, ```North America```, and ```North America``` as our possible labels.\n",
        "\n",
        "### **Exercise: Train the model using the standard pipeline you have mastered!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxYkappX6Y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "246ca731-3c4b-43f8-92ce-756c96a507e9"
      },
      "source": [
        "lm = linear_model.LogisticRegression(\n",
        "    multi_class=\"multinomial\", max_iter=1000,\n",
        "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
        "lm.fit(X_train,y_train)\n",
        "\n",
        "#### FILL IN ########\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(fit_intercept=False, max_iter=1000,\n",
              "                   multi_class='multinomial', random_state=42, solver='saga',\n",
              "                   tol=0.001)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;, random_state=42, solver=&#x27;saga&#x27;,\n",
              "                   tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;, random_state=42, solver=&#x27;saga&#x27;,\n",
              "                   tol=0.001)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoMF1rGisxC"
      },
      "source": [
        "## Testing/Evaluation\n",
        "\n",
        "In addition to printing the accuracy of a model, we can also use a *confusion matrix* to see how well the model performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXLmY1hfqGT7"
      },
      "source": [
        "###**Exercise: Evaluate the model on the test set.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYGTYPopp5WR",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf4e265-5bdf-4f83-abf5-8c4067339fdc"
      },
      "source": [
        "# Predict on the test set.\n",
        "y_pred = lm.predict(X_test)\n",
        "# Compute accuracy.\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy: %\", accuracy)\n",
        "\n",
        "# Compute confusion matrix.\n",
        "confusion_mat = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
        "confusion_mat.columns = [c + ' predicted' for c in lm.classes_]\n",
        "confusion_mat.index = [c + ' true' for c in lm.classes_]\n",
        "\n",
        "print(confusion_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: % 0.9545454545454546\n",
            "                    Asia predicted  North America predicted  Oceania predicted\n",
            "Asia true                       24                        1                  0\n",
            "North America true               1                       15                  1\n",
            "Oceania true                     0                        0                 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwrfLGMKaG4"
      },
      "source": [
        "# Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAgFs2spqoHF"
      },
      "source": [
        "***Great job!*** You built a pretty accurate model that uses genomic data to predict what country a SARS-CoV-2 sample comes from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsiiqHD5qzOg",
        "cellView": "form"
      },
      "source": [
        "#@title #### **Exercise: To wrap up, write a couple of sentences explaining how your model performed.**\n",
        "Response = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}